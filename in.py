import nltk
import os
import zipfile
from urllib.request import urlretrieve
from urllib.error import URLError

# æ¸…åé•œåƒæºçš„ punkt_tab ä¸‹è½½åœ°å€ï¼ˆå›½å†…é€Ÿåº¦å¿«ï¼Œä¸ä¼šæ–­è¿ï¼‰
PUNKT_TAB_URL = "https://mirrors.tuna.tsinghua.edu.cn/nltk_data/packages/tokenizers/punkt_tab.zip"
# NLTK æ•°æ®å­˜æ”¾ç›®å½•ï¼ˆé»˜è®¤è·¯å¾„ï¼Œç¡®ä¿ Python èƒ½æ‰¾åˆ°ï¼‰
NLTK_DATA_DIR = os.path.join(os.path.expanduser("~"), "AppData", "Roaming", "nltk_data")
# è§£å‹åçš„ç›®æ ‡ç›®å½•
TARGET_DIR = os.path.join(NLTK_DATA_DIR, "tokenizers", "punkt_tab")

def download_and_extract_punkt_tab():
    """ç”¨æ¸…åé•œåƒæºä¸‹è½½å¹¶è§£å‹ punkt_tab æ¨¡å‹"""
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs(NLTK_DATA_DIR, exist_ok=True)
    os.makedirs(os.path.join(NLTK_DATA_DIR, "tokenizers"), exist_ok=True)
    
    # ä¸‹è½½ä¸´æ—¶æ–‡ä»¶
    zip_path = os.path.join(NLTK_DATA_DIR, "punkt_tab.zip")
    print(f"ğŸ“¥ æ­£åœ¨ä»æ¸…åé•œåƒæºä¸‹è½½ punkt_tab...")
    print(f"URL: {PUNKT_TAB_URL}")
    
    try:
        # ä¸‹è½½æ–‡ä»¶ï¼ˆæ˜¾ç¤ºè¿›åº¦ï¼‰
        def progress_hook(count, block_size, total_size):
            if total_size > 0:
                percent = (count * block_size) / total_size * 100
                print(f"â³ ä¸‹è½½è¿›åº¦: {percent:.1f}%", end="\r")
        
        urlretrieve(PUNKT_TAB_URL, zip_path, reporthook=progress_hook)
        print("\nğŸ“¥ ä¸‹è½½å®Œæˆï¼å¼€å§‹è§£å‹...")
        
        # è§£å‹æ–‡ä»¶
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(os.path.join(NLTK_DATA_DIR, "tokenizers"))
        
        # åˆ é™¤ä¸´æ—¶å‹ç¼©åŒ…
        os.remove(zip_path)
        print(f"âœ… è§£å‹å®Œæˆï¼æ¨¡å‹å·²ä¿å­˜åˆ°: {TARGET_DIR}")
        return True
    
    except URLError as e:
        print(f"\nâŒ ä¸‹è½½å¤±è´¥ï¼šç½‘ç»œè¿æ¥é”™è¯¯ - {str(e)}")
        return False
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥ï¼š{str(e)}")
        return False

def check_punkt_tab():
    """æ£€æŸ¥ punkt_tab æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨"""
    try:
        # éªŒè¯ NLTK èƒ½å¦æ‰¾åˆ°è¯¥èµ„æº
        nltk.data.find('tokenizers/punkt_tab/english.pickle')
        return True
    except LookupError:
        return False

def test_tokenize():
    """æµ‹è¯•åˆ†è¯åŠŸèƒ½æ˜¯å¦æ­£å¸¸"""
    try:
        from nltk.tokenize import word_tokenize
        test_sentence = "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œæˆ‘æƒ³å»å…¬å›­æ•£æ­¥ï¼Œè¿˜æƒ³åƒç‚¸é¸¡ï¼"
        words = word_tokenize(test_sentence)
        print(f"\nâœ… åˆ†è¯æµ‹è¯•æˆåŠŸï¼")
        print(f"åŸå§‹å¥å­ï¼š{test_sentence}")
        print(f"åˆ†è¯ç»“æœï¼š{words}")
        return True
    except Exception as e:
        print(f"\nâŒ åˆ†è¯æµ‹è¯•å¤±è´¥ï¼š{str(e)}")
        return False

if __name__ == "__main__":
    print("=== NLTK punkt_tab æ¨¡å‹é…ç½®å·¥å…·ï¼ˆPython 3.10ï¼‰===")
    
    # 1. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
    if check_punkt_tab():
        print("âœ… punkt_tab æ¨¡å‹å·²å­˜åœ¨ï¼Œæ— éœ€ä¸‹è½½ï¼")
    else:
        # 2. ä¸‹è½½å¹¶è§£å‹æ¨¡å‹
        if not download_and_extract_punkt_tab():
            print("\nâŒ æ¨¡å‹é…ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•ï¼")
            exit(1)
    
    # 3. æµ‹è¯•åˆ†è¯åŠŸèƒ½
    if test_tokenize():
        print("\nğŸ‰ æ‰€æœ‰é…ç½®å®Œæˆï¼å¯ä»¥æ­£å¸¸ä½¿ç”¨åˆ†è¯åŠŸèƒ½äº†ï½")
    else:
        print("\nâŒ é…ç½®æœªå®Œæˆï¼Œè¯·é‡æ–°è¿è¡Œè„šæœ¬ï¼")